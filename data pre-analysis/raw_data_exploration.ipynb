{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring CSL daily dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'S000007_P0003_T00', 'length': 55, 'label_gloss': ['他', '谁'], 'label_char': ['他', '是', '谁', '？'], 'label_word': ['他', '是', '谁', '？'], 'label_postag': ['r', 'v', 'v', 'w'], 'signer': 3, 'time': 0}\n",
      "20654\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "'''\n",
    "name: video name\n",
    "length: the number of frames in the video\n",
    "label_gloss: gloss sequence stored in [List] for sign language recognition\n",
    "label_char: char sequence stored in [List] for sign language translation. In our experiments, we use this as SLT target.\n",
    "label_word: word sequence stored in [List] for sign language translation. Just for reference.\n",
    "signer: the id of some signer. It starts from 0. ---> does the signer eve\n",
    "time: how many times the same signer performs the same sentence. It starts from 0. Actually, no signer performs the same sentence twice.\n",
    "gloss_map: vocabulary for glosses\n",
    "char_map: vocabulary for chars\n",
    "'''\n",
    "\n",
    "CSL_path = \"../../../CSL-Daily/sentence_label/csl2020ct_v2.pkl\"\n",
    "with open(CSL_path, 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "#print(data['info'][1:10])\n",
    "print(data['info'][21\n",
    "                   ])\n",
    "# The name you're looking for\n",
    "target_name = 'S000005_P0000_T00'\n",
    "\n",
    "# Finding the index\n",
    "index = next((i for i, item in enumerate(data['info']) if item[\"name\"] == target_name), None)\n",
    "print(len(data['info']))\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 20654 videos of different sentences\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are a total of {len(data['info'])} videos of different sentences\")\n",
    "## note that for each video also need to take note of max length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Phoenix dataset\n",
    "- It was easier to process this\n",
    "- The csv annotations are processed into a new pickle dictionary\n",
    "- When loading the dataset into the dataloader, enter the pickle dictionary to extract the foldernames so that python knows which folder to enter in order to extract the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the resulting new pickle dictionary consisting of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/annotations/processed/labels_dev.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_42984\\3498616473.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlabel_dev_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'.../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/annotations/processed/labels_dev.pkl'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Load the pickle file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_dev_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpkl_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpkl_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/annotations/processed/labels_dev.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "label_dev_path = '.../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/annotations/processed/labels_dev.pkl'\n",
    "# Load the pickle file\n",
    "with open(label_dev_path, 'rb') as pkl_file:\n",
    "    data = pickle.load(pkl_file)\n",
    "\n",
    "# Now 'data' contains the dictionary or object that was stored in the pickle file\n",
    "print(data['info'][0])\n",
    "print(data['max_length'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data type: 7096\n",
      "Dev data type: 519\n",
      "Test data type: 642\n"
     ]
    }
   ],
   "source": [
    "train_path = '../../../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/annotations/processed/labels_train.pkl'\n",
    "dev_path =  '../../../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/annotations/processed/labels_dev.pkl'\n",
    "test_path = '../../../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/annotations/processed/labels_test.pkl'\n",
    "\n",
    "# Function to load a pickle file\n",
    "def load_pickle(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "# Load each file\n",
    "train_data = load_pickle(train_path)\n",
    "dev_data = load_pickle(dev_path)\n",
    "test_data = load_pickle(test_path)\n",
    "\n",
    "# Example: Print the type of data loaded to confirm\n",
    "print(f\"Train data type: {len(train_data['info'])}\")\n",
    "print(f\"Dev data type: {len(dev_data['info'])}\")\n",
    "print(f\"Test data type: {len(test_data['info'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data type: 18401\n",
      "Dev data type: 1077\n",
      "Test data type: 1176\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_path =  '../../../CSL-Daily/sentence_label/processed/labels_train.pkl'\n",
    "dev_path = '../../../CSL-Daily/sentence_label/processed/labels_dev.pkl'\n",
    "test_path = '../../../CSL-Daily/sentence_label/processed/labels_test.pkl'\n",
    "\n",
    "# Function to load a pickle file\n",
    "def load_pickle(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        data = pickle.load(file)\n",
    "    return data\n",
    "\n",
    "# Load each file\n",
    "train_data = load_pickle(train_path)\n",
    "dev_data = load_pickle(dev_path)\n",
    "test_data = load_pickle(test_path)\n",
    "\n",
    "# Example: Print the type of data loaded to confirm\n",
    "print(f\"Train data type: {len(train_data['info'])}\")\n",
    "print(f\"Dev data type: {len(dev_data['info'])}\")\n",
    "print(f\"Test data type: {len(test_data['info'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
