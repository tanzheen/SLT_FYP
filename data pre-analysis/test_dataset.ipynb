{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *torch\n",
    "from pickletools import optimize\n",
    "# from sched import scheduler\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.optim import lr_scheduler as scheduler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# *transformers\n",
    "from transformers import MBartForConditionalGeneration, MBartTokenizer, MBartConfig\n",
    "\n",
    "\n",
    "import utils as utils\n",
    "\n",
    "\n",
    "# *basic\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import json, datetime\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "import random\n",
    "import wandb\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import math\n",
    "import sys\n",
    "from typing import Iterable, Optional\n",
    "from loguru import logger\n",
    "\n",
    "from sacrebleu.metrics import BLEU, CHRF, TER\n",
    "\n",
    "# *timm\n",
    "from timm.optim import create_optimizer\n",
    "from timm.scheduler import create_scheduler\n",
    "from timm.utils import NativeScaler\n",
    "from timm.loss import SoftTargetCrossEntropy\n",
    "from timm.optim import AdamW\n",
    "\n",
    "# visualization\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from PIL import Image\n",
    "import argparse\n",
    "from hpman.m import _\n",
    "import hpargparse\n",
    "\n",
    "# global definition\n",
    "from definition import *\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=16, clip_grad=None, config='./config_gloss_free_CSL daily.yaml', cooldown_epochs=10, decay_epochs=30, decay_rate=0.1, device='cuda', dist_url='env://', entity=None, epochs=80, eval=False, finetune='c:\\\\Users\\\\User\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-v2-37492a5B4THCMXA7j.json', hp_detail=False, hp_exit=False, hp_list=None, hp_load=None, hp_save=None, hp_serial_format='auto', input_size=224, local_rank=0, log_all=False, loss_lambda=1.0, lr=0.001, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, min_lr=1e-08, momentum=0.9, noise_rate=0.15, noise_type='omit_last', num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-09, output_dir='', patience_epochs=10, pin_mem=True, project='VLP', random_shuffle=False, resize=256, resume='', sched='cosine', seed=0, start_epoch=0, training_refurbish=True, warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.0, world_size=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from prep_args import * \n",
    "parser = argparse.ArgumentParser('Visual-Language-Pretraining (VLP) V2 scripts', parents=[get_args_parser()])\n",
    "\n",
    "hpargparse.bind(parser, _)\n",
    "args = parser.parse_args()\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'GFSLT-VLP CSL-Daily',\n",
       " 'data': {'train': '../../CSL-Daily/sentence_label/processed/labels_train.pkl',\n",
       "  'dev': '../../CSL-Daily/sentence_label/processed/labels_dev.pkl',\n",
       "  'test': '../../CSL-Daily/sentence_label/processed/labels_test.pkl',\n",
       "  'img_path': '../../CSL-Daily/sentence/frames_512x512',\n",
       "  'max_length': 300},\n",
       " 'training': {'wandb': 'disabled', 'scale_embedding': False},\n",
       " 'model': {'transformer': './pretrain_models/CSL/MBart_trimmed',\n",
       "  'visual_encoder': './pretrain_models/CSL/mytran',\n",
       "  'sign_proj': True}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(args.config, 'r+', encoding='utf-8') as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[250004,      6, 100013, 101676,  27683,   1344,     30,      2,      1],\n",
      "        [250004,      6,   8513,  83757, 101676,  27683,   1344,     30,      2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "tensor([[250004,      6, 100013, 101676,  27683,   1344,     30,      2,      1],\n",
      "        [250004,      6,   8513,  83757, 101676,  27683,   1344,     30,      2]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors: 100%|██████████| 2.44G/2.44G [01:20<00:00, 30.5MB/s]\n",
      "C:\\Users\\User\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.7_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python37\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\User\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading generation_config.json: 100%|██████████| 261/261 [00:00<00:00, 65.3kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是一个例子句子。\n"
     ]
    }
   ],
   "source": [
    "from transformers import MBart50Tokenizer, MBartForConditionalGeneration\n",
    "\n",
    "# Load the MBART tokenizer\n",
    "tokenizer = MBart50Tokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "# Example: Chinese sentences from the CSL-daily dataset\n",
    "texts = [\"这是一个例子句子。\", \"这是另一个例子句子。\"]\n",
    "\n",
    "# Tokenize the Chinese text data\n",
    "tokenized_texts = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "print (tokenized_texts)\n",
    "input_ids = tokenized_texts['input_ids']\n",
    "print(input_ids)\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "output = model.generate(input_ids, max_length=50)\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import data_classes\n",
    "importlib.reload(data_classes)\n",
    "from data_classes import * \n",
    "\n",
    "train_dataset = S2T_Dataset(tokenizer, config, args, 'train', training_refurbish = False)\n",
    "print(type(train_dataset.data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000000.jpg', '000001.jpg', '000002.jpg', '000003.jpg', '000004.jpg', '000005.jpg', '000006.jpg', '000007.jpg', '000008.jpg', '000009.jpg', '000010.jpg', '000011.jpg', '000012.jpg', '000013.jpg', '000014.jpg', '000015.jpg', '000016.jpg', '000017.jpg', '000018.jpg', '000019.jpg', '000020.jpg', '000021.jpg', '000022.jpg', '000023.jpg', '000024.jpg', '000025.jpg', '000026.jpg', '000027.jpg', '000028.jpg', '000029.jpg', '000030.jpg', '000031.jpg', '000032.jpg', '000033.jpg', '000034.jpg', '000035.jpg', '000036.jpg', '000037.jpg', '000038.jpg', '000039.jpg', '000040.jpg', '000041.jpg', '000042.jpg', '000043.jpg', '000044.jpg', '000045.jpg', '000046.jpg', '000047.jpg', '000048.jpg', '000049.jpg', '000050.jpg', '000051.jpg']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 3, 224, 224])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets:\n",
      "#total train set: 18401.\n",
      "#total dev set: 1077.\n",
      "#total test set: 1176.\n"
     ]
    }
   ],
   "source": [
    "import prep_dataloaders\n",
    "importlib.reload(prep_dataloaders)\n",
    "from prep_dataloaders import * \n",
    "trainloader, devloader, testloader = create_dataloaders(config, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
