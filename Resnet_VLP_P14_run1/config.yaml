experiment:
  project: Resnet_VLP_P14
  name: Resnet_VLP_P14_run1
  output_dir: ../Resnet_VLP_P14_run1
  save_every: 1
  log_every: 0.1
  eval_every: 1
  translate_every: 0.25
  log_grad_norm_every: 0.1
  resume: true
  init_weight: null
  logging_dir: ../Resnet_VLP_P14_run1\logs
model:
  tokenizer: ./pretrain_models/MBart_proun
  transformer: ./pretrain_models/MBart_proun
  visual_encoder: ./pretrain_models/mytran
  sign_proj: true
  after_pretrained: ./pretrain_models/mytran
dataset:
  name: PHOENIX2014T
  lang: de_DE
  train: ../../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/annotations/processed/labels_train.pkl
  dev: ../../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/annotations/processed/labels_dev.pkl
  test: ../../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/annotations/processed/labels_test.pkl
  img_path: ../../PHOENIX-2014-T-release-v3/PHOENIX-2014-T/features/fullFrame-210x260px
  max_length: 300
  params:
    num_workers: 4
  preprocessing:
    crop_size: 224
    resize_shorter_edge: 256
    random_crop: true
    random_flip: true
    person_size: 410
optimizer:
  name: adamw
  params:
    learning_rate: 0.0001
    beta1: 0.9
    beta2: 0.99
    weight_decay: 0.0001
lr_scheduler:
  scheduler: cosine
  params:
    learning_rate: ${optimizer.params.learning_rate}
    warmup_steps: 4000
    end_lr: 1.0e-05
training:
  gradient_accumulation_steps: 8
  per_gpu_batch_size: 2
  mixed_precision: 'no'
  enable_tf32: true
  enable_wandb: true
  use_ema: false
  seed: 42
  num_translated_images: 4
  max_grad_norm: 1.0
  num_epochs: 32
  scale_embedding: false
config: configs/stage2/Resnet_SLT_P14_config.yaml
--experiment:
  project: Resnet_VLP_P14
  name: Resnet_VLP_P14_run1
  output_dir: Resnet_VLP_P14_run1
