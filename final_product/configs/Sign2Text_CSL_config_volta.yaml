experiment:
  project: "Sign2Text"
  name: "Sign2Text_run1"
  output_dir: "/scratch2/e0724993/Sign2Text_run1"
  translate_every: 0.5
  save_every: 0.001
  log_every: 0.001
  eval_every: 1
  log_grad_norm_every: 0.01
  resume: True
  init_weight: ""

model:
  vq_model:
    codebook_size: 4096
    token_size: 12
    use_l2_norm: True
    commitment_cost: 0.25
    # vit arch
    vit_enc_model_size: "large"
    vit_dec_model_size: "large"
    vit_enc_patch_size: 16
    vit_dec_patch_size: 16
    num_latent_tokens: 32
    finetune_decoder: False
    pretrained_tokenizer_weight: "maskgit-vqgan-imagenet-f16-256.bin"
    init_weight: "/hpctmp/e0724993/TiTok_weights/ema_model/pytorch_model.bin"

  MBart_model:
    init_weight: /hpctmp/e0724993/mbart_model # need to find the model weights

losses:
  quantizer_weight: 1.0

dataset:
  name: CSL-Daily
  lang: zh_CN
  train: /hpctmp/e0724993/CSL-Daily/sentence_label/processed/labels_train.pkl
  dev: /hpctmp/e0724993/CSL-Daily/sentence_label/processed/labels_dev.pkl
  test: /hpctmp/e0724993/CSL-Daily/sentence_label/processed/labels_test.pkl
  img_path: /hpctmp/e0724993/CSL-Daily/sentence/frames_512x512/ # + <train/dev/test> + <video_name>
  max_length: 300
  params:
    num_workers: 4
  preprocessing:
    crop_size: 256
    resize_shorter_edge: 256
    random_crop: True
    random_flip: True
    person_size: 410

optimizer:
  name: adamw
  params:
    learning_rate: 1e-5
    beta1: 0.9
    beta2: 0.99
    weight_decay: 1e-4

lr_scheduler:
  scheduler: "cosine"
  params:
    learning_rate: ${optimizer.params.learning_rate}
    warmup_steps: 10_000
    end_lr: 1e-5

training:
  gradient_accumulation_steps: 1
  per_gpu_batch_size: 4
  mixed_precision: "fp16"
  enable_tf32: True
  enable_wandb: False
  use_ema: True
  seed: 42
  num_translated_images: 4
  max_grad_norm: 1.0
  num_epochs: 10
  frame_every: 5
  tokenizer: /hpctmp/e0724993/mbart_model # volta server cannot download
